# ğŸ¤– AI Chatbot for FHTW â€“ v2.0

A context-aware, OpenAI-powered chatbot designed to answer administrative and academic queries using university-specific documents and Moodle links. It uses semantic search and GPT-based generation to deliver fast, filtered, and source-aware answers.

---

## ğŸš€ Features

- ğŸ” Retrieval-Augmented Generation (RAG) using ChromaDB + GPT
- ğŸ’¬ GPT-4o-powered answer generation via LangChain
- ğŸ§  Context parsing with template-driven prompts
- ğŸ“„ Processes official documents (PDF) and Moodle links
- âœ… Feedback collection with thumbs-up/down and reasons
- ğŸ§‘â€ğŸ’» User session logging to CSV for analysis
- ğŸ–¥ï¸ GUI built using `tkinter` for local interaction

---

## ğŸ›  Architecture Overview

```text
PDFs + Moodle Links
        â†“
Preprocessing (abbreviation cleanup)
        â†“
ChromaDB vector store (semantic chunks)
        â†“
RAG â†’ LangChain + GPT-4o
        â†“
Answer generation + source attribution
        â†“
GUI Interface + Feedback Collection
```

---

## ğŸ“¦ Dependencies

Install all required packages using:

```bash
pip install -r requirements.txt
```

Key libraries used:

- `langchain`, `langchain-community`, `openai`
- `chromadb`, `multilingual-pdf2text`
- `tkinter`, `nltk`, `spacy`, `torch`
- `fastapi`, `typer`, `pyngrok`

Set your OpenAI API key in a `.env` file under `config/`:

```env
OPENAI_API_KEY=your-openai-key-here
```

---

## âš™ï¸ Getting Started

### 1. Create Chroma Vector DB

```bash
python create_database.py
```

This will:
- Process all PDF files in `data/books`
- Generate embeddings
- Store them in `config/db/chroma25`

### 2. Launch the Chatbot GUI

```bash
python app.py
```

The application opens a GUI where users can type questions and receive AI-generated responses with source references.

---

## ğŸ§  Query Logic

- Uses a **Retrieval-Augmented Generation (RAG)** pipeline
- Retrieves semantically relevant content from ChromaDB
- Injects the results into a prompt using LangChain
- GPT-4o generates a response strictly based on the context
- If no match is found, the chatbot responds accordingly

---

## ğŸ›¡ï¸ Hallucination Prevention

This chatbot applies multiple controls to minimize hallucinations:

- `temperature=0`: ensures deterministic, non-random answers
- Carefully engineered prompts to restrict the model to retrieved context only
- If the answer cannot be supported by the context, the bot responds:
  > *"No information available regarding this topic in the source documents."*

This enforces factual accuracy and guards against model guesswork.

---

## ğŸ§¾ Feedback Logging

User interactions are saved in CSV format, including:

```csv
ID, Question, Answer, Thumbsup, Thumbsdown, Reason, ResponseTime
```

Files are stored in the `user-testing/` directory and auto-generated per session.

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ app.py                  # GUI entry point
â”œâ”€â”€ query_data.py          # RAG + GPT answer generator
â”œâ”€â”€ create_database.py     # PDF embedding & ChromaDB setup
â”œâ”€â”€ clean_abriviations.py  # German abbreviation normalizer
â”œâ”€â”€ settings.py            # Configuration and path resolver
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ config/
â”‚   â””â”€â”€ .env                # OpenAI API key configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ books/              # Source PDFs
â”‚   â””â”€â”€ links/              # Moodle links in JSON format
â””â”€â”€ user-testing/          # Saved user logs (CSV)
```

---

## ğŸ” Notes

- Place all source PDFs under `data/books/`
- Moodle links must be stored as a JSON file at `data/links/links.json`
- Output logs from chatbot interactions are saved automatically

---

## ğŸ“Œ Version

**v2.0** â€” Powered by OpenAI GPT-4o with a modular RAG-based backend and offline GUI support.

---

## ğŸ“œ License

This project is intended for academic use at FHTW. Not licensed for commercial distribution.
